# Minecraft Bot Session - 2026-02-08

## What We Accomplished Today

### 1. Conversational AI Mode (Completed)
- **Goal:** Transform bot from command-driven to conversational autonomous AI
- **Implementation:** Subagent built conversation queue system
  - Bot detects mentions â†’ queues to `conversations.json`
  - OpenClaw writes responses â†’ `responses.json`
  - Bot polls and speaks responses
- **Status:** âœ… Technically working, but too slow/manual

### 2. Silenced Internal Announcements (Completed)
- **Problem:** Bot was spamming chat with internal goals ("need pickaxe", "Hello World!")
- **Fix:** Disabled `announceActions`, removed spawn greeting, silenced "Need X" messages
- **Commits:**
  - `c935b78` - Silence internal goal announcements
  - `e128c79` - Fix mention detection (match first name part)
- **Status:** âœ… Bot now works silently, only speaks when responding to players

### 3. Discovered Core Problem
- **Issue:** Conversational queue system is too indirect/slow
  - Bot â†’ file â†’ manual polling â†’ response â†’ file â†’ bot
  - Not natural, feels robotic
- **Root cause:** OpenClaw (Nova/LLM) and bot are disconnected processes

### 4. Designed Direct Integration (Design Phase)
- **Solution:** OpenClaw becomes the bot's brain directly
- **Architecture:** File-based API for real-time control
  - `events.json` - Bot writes events (chat, damage, goals)
  - `responses.json` - OpenClaw writes chat messages  
  - `commands.json` - OpenClaw writes bot actions
  - `state.json` - Bot writes current state + **rich world perception**
- **Key insight:** Use structured Mineflayer data instead of screenshots
  - Blocks nearby (counts + types)
  - Entities (players, mobs) with distances
  - Line of sight (what bot is looking at)
  - Features (caves, villages, ravines)
  - Light/time/biome data
- **Document:** `OPENCLAW-INTEGRATION.md`
- **Status:** ðŸ“ Design complete, ready to implement

---

## Current State

### What's Working
âœ… Bot spawns silently (no spam)
âœ… Bot runs autonomously (gathers wood, mines, survives)
âœ… Conversation detection (bot queues mentions)
âœ… Response system (bot speaks queued responses)
âœ… All 23 phases of bot capabilities (mining, crafting, building, etc.)

### What's Not Working
âŒ Bot responses feel robotic (queue system too slow)
âŒ OpenClaw can't see the world properly (no perception data yet)
âŒ OpenClaw can't control bot naturally (no command execution yet)
âŒ Bot sometimes gets stuck (mining water, pathfinding bugs)

### Current Bot Instance
- **Name:** Nova_AI
- **Server:** 187.77.2.50:25568 (vanilla Minecraft)
- **Status:** Running (session: nova-ocean, pid 8980)
- **Mode:** Autonomous survival + conversational (queue-based)

---

## Tomorrow's Implementation Plan

### Phase 1: Bot-Side Changes (bot.js)

#### 1.1 Generate Rich Perception Data
**File:** `bot.js` â†’ `generatePerception()` function

```javascript
function generatePerception() {
  // Find blocks within 32 blocks
  const nearbyBlocks = bot.findBlocks({
    matching: (block) => block.name !== 'air',
    maxDistance: 32,
    count: 1000
  });
  
  // Count block types
  const blockCounts = {};
  nearbyBlocks.forEach(pos => {
    const block = bot.blockAt(pos);
    blockCounts[block.name] = (blockCounts[block.name] || 0) + 1;
  });
  
  // Get entities
  const entities = Object.values(bot.entities)
    .filter(e => e.position && e.position.distanceTo(bot.entity.position) < 32)
    .map(e => ({
      type: e.type,
      name: e.name || e.username,
      distance: Math.floor(bot.entity.position.distanceTo(e.position)),
      health: e.health
    }));
  
  // What are we looking at?
  const lookingAt = bot.blockAtCursor(32);
  
  return {
    lookingAt: lookingAt ? {
      type: lookingAt.name, 
      distance: Math.floor(bot.entity.position.distanceTo(lookingAt.position))
    } : null,
    blocksNearby: blockCounts,
    entities: entities,
    lightLevel: bot.blockAt(bot.entity.position)?.light || 0,
    timeOfDay: getTimeOfDay(bot.time.timeOfDay),
    biome: bot.blockAt(bot.entity.position)?.biome?.name || 'unknown'
  };
}
```

#### 1.2 Update State Broadcasting
**File:** `bot.js` â†’ Update `setInterval` that writes `state.json`

Add perception data to state output every 5 seconds.

#### 1.3 Command Execution System
**File:** `bot.js` â†’ New `executeOpenClawCommands()` function

```javascript
function executeOpenClawCommands() {
  if (!fs.existsSync(COMMANDS_FILE)) return;
  
  const commands = JSON.parse(fs.readFileSync(COMMANDS_FILE, 'utf8'));
  if (!commands || commands.length === 0) return;
  
  // Execute each command
  for (const cmd of commands) {
    console.log(`[OpenClaw] Executing: ${cmd.action}`);
    executeCommand(cmd); // Use existing command system
  }
  
  // Clear commands after execution
  fs.writeFileSync(COMMANDS_FILE, '[]');
}

// Poll every 2 seconds
setInterval(executeOpenClawCommands, 2000);
```

#### 1.4 Better Event Logging
**File:** `bot.js` â†’ Enhance `logEvent()` to write to `events.json`

Include more context in chat events:
- Player position relative to bot
- What bot was doing at the time
- Nearby entities/threats

### Phase 2: OpenClaw Tool (minecraft skill)

#### 2.1 Create Skill Structure
```
workspace/skills/minecraft/
â”œâ”€â”€ SKILL.md          # Documentation for OpenClaw
â”œâ”€â”€ minecraft.js      # Node.js implementation
â””â”€â”€ examples/
    â””â”€â”€ chat-example.js
```

#### 2.2 Implement minecraft.js
```javascript
const fs = require('fs');
const path = require('path');

const DATA_DIR = '/data/minecraft-bot';
const STATE_FILE = path.join(DATA_DIR, 'state.json');
const EVENTS_FILE = path.join(DATA_DIR, 'events.json');
const RESPONSES_FILE = path.join(DATA_DIR, 'responses.json');
const COMMANDS_FILE = path.join(DATA_DIR, 'commands.json');

let lastEventId = 0;

module.exports = {
  // Get current bot status + world perception
  status() {
    return JSON.parse(fs.readFileSync(STATE_FILE, 'utf8'));
  },
  
  // Poll for new events (chat, damage, etc.)
  poll() {
    const events = JSON.parse(fs.readFileSync(EVENTS_FILE, 'utf8'));
    const newEvents = events.filter(e => e.id > lastEventId);
    if (newEvents.length > 0) {
      lastEventId = Math.max(...newEvents.map(e => e.id));
    }
    return newEvents;
  },
  
  // Speak in Minecraft chat
  chat(message) {
    const responses = JSON.parse(fs.readFileSync(RESPONSES_FILE, 'utf8'));
    responses.push({
      id: Date.now(),
      message: message,
      timestamp: new Date().toISOString()
    });
    fs.writeFileSync(RESPONSES_FILE, JSON.stringify(responses, null, 2));
  },
  
  // Execute bot command
  command(action, params = {}) {
    const commands = JSON.parse(fs.readFileSync(COMMANDS_FILE, 'utf8'));
    commands.push({
      action: action,
      ...params,
      timestamp: new Date().toISOString()
    });
    fs.writeFileSync(COMMANDS_FILE, JSON.stringify(commands, null, 2));
  }
};
```

#### 2.3 Write SKILL.md
Document how to use the minecraft tool from OpenClaw sessions.

### Phase 3: OpenClaw Heartbeat Integration

#### 3.1 Update HEARTBEAT.md
Add Minecraft polling to heartbeat checks:

```markdown
## Minecraft Bot Check (every heartbeat)

1. Poll events: `const events = await minecraft.poll()`
2. If chat event from player â†’ respond naturally
3. Check bot health/food â†’ command if needed
4. Check for interesting events (found diamonds, under attack, etc.)
```

#### 3.2 Test Loop
1. Player says "hey nova, what are you doing?"
2. Bot writes to events.json
3. Next heartbeat â†’ OpenClaw polls â†’ sees event
4. OpenClaw responds via `minecraft.chat()` + `minecraft.command()` if needed
5. Bot executes and speaks

### Phase 4: Polish & Testing

#### 4.1 Fix Pathfinding Bugs
- Bot getting stuck mining water
- Better obstacle avoidance

#### 4.2 Tune Polling Frequency
- How often should OpenClaw check events? (10s? 30s?)
- Balance between responsiveness and API cost

#### 4.3 Autonomous Fallback
- Bot should continue survival goals when OpenClaw is idle
- Only interrupt autonomy when player chats or emergency

#### 4.4 Test Scenarios
- [ ] Player chats â†’ Nova responds naturally
- [ ] Player asks bot to do something â†’ Nova commands bot
- [ ] Combat scenario â†’ Nova takes control
- [ ] Idle â†’ Bot continues autonomous survival

---

## Key Files & Commits

### Today's Commits
- `a49fa4d` - Transform bot from command-driven tool to autonomous social AI (subagent work)
- `6ec318f` - Add documentation for conversational AI mode (subagent work)
- `c935b78` - Silence internal goal announcements
- `e128c79` - Fix mention detection (match first name part)
- `4600d98` - Add OpenClaw direct integration design
- `bea0ea9` - Update integration design: structured world perception

### Important Files
- `/data/.openclaw/workspace/openclaw-minecraft-plugin/` - Bot repo
  - `bot.js` - Main bot code (5669 lines)
  - `OPENCLAW-INTEGRATION.md` - Implementation design (tomorrow's plan)
  - `AUTONOMOUS-SOCIAL-AI-PLAN.md` - Original conversational mode plan
- `/data/minecraft-bot/` - Shared state directory
  - `events.json` - Bot â†’ OpenClaw events
  - `responses.json` - OpenClaw â†’ Bot chat responses
  - `commands.json` - OpenClaw â†’ Bot actions
  - `state.json` - Bot status + world perception
  - `world-memory.json` - Bot's persistent memory

### Server Info
- **Vanilla Minecraft:** 187.77.2.50:25568
- **Docker container:** minecraft-vanilla
- **Bot process:** Running as background task (nova-ocean session)

---

## Lessons Learned

1. **Queue-based conversation is too slow** - Need direct integration for natural chat
2. **Structured data > screenshots** - Mineflayer provides all world info already
3. **Silence is golden** - Autonomous bots shouldn't announce every thought
4. **Integration is key** - OpenClaw as brain + bot as body = natural AI player

---

## Tomorrow's Goal

**Get Nova playing Minecraft naturally:**
- See the world (rich perception data)
- Chat naturally (direct responses)
- Control her body (command execution)
- Feel alive (real-time, contextual, personality-driven)

**Estimated time:** 2-3 hours implementation + testing

---

**Status:** Ready to implement tomorrow
**Next session:** Continue with Phase 1 (bot-side changes)
